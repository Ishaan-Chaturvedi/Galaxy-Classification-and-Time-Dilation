{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting Drive"
      ],
      "metadata": {
        "id": "cMAtrrUgdQzu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "MM7W9wrIXA8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4da1281-1dd1-4523-9c87-86ff5b214dda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Path For Model and Data"
      ],
      "metadata": {
        "id": "R3YQi3wLeMJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputdir='/content/drive/MyDrive/'\n",
        "inputpath=outputdir+'dummytest.csv'\n",
        "outputmodelpath=outputdir+'model.pth'"
      ],
      "metadata": {
        "id": "TyvveqlXdbRO"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies"
      ],
      "metadata": {
        "id": "SYGa_dxTewCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#For decision tree scikit learn\n",
        "from sklearn.ensemble import RandomForestClassifier as forest\n",
        "\n",
        "#for Neural net\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from sklearn.preprocessing import LabelEncoder as le\n",
        "from scipy.special import softmax\n",
        "from sklearn.model_selection import StratifiedKFold as SKF\n",
        "\n"
      ],
      "metadata": {
        "id": "fIp9ZLCHezB4"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model"
      ],
      "metadata": {
        "id": "if_0rUNjg09J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading encodings\n",
        "le1=le()\n",
        "le1.classes_=np.load(outputdir+'encodings.npy',allow_pickle=True)"
      ],
      "metadata": {
        "id": "U0ZSuq_stRH0"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining all models to form a final model\n",
        "class final_model(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model1=torch.load(outputdir+'model0.pth')\n",
        "        self.model1.eval()\n",
        "        self.model2=torch.load(outputdir+'model1.pth')\n",
        "        self.model2.eval()\n",
        "        self.model3=torch.load(outputdir+'model2.pth')\n",
        "        self.model3.eval()\n",
        "        self.model4=torch.load(outputdir+'model3.pth')\n",
        "        self.model4.eval()\n",
        "        self.model5=torch.load(outputdir+'model4.pth')\n",
        "        self.model5.eval()\n",
        "        self\n",
        "  def forward(self,X):\n",
        "    with torch.no_grad():\n",
        "      output=(self.model1(X)+self.model2(X)+self.model3(X)+self.model4(X)+self.model5(X))/5\n",
        "      output=softmax(output).argmax(axis=1)\n",
        "      k=np.array(le1.inverse_transform(output))\n",
        "\n",
        "      return output,k"
      ],
      "metadata": {
        "id": "dau4jOFlon-T"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=torch.load(outputmodelpath)"
      ],
      "metadata": {
        "id": "SJtUito1g0ti"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(ytest,ypred):\n",
        "  return sum(ypred==ytest)/len(ytest)"
      ],
      "metadata": {
        "id": "KxLhEim1vNkf"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Function"
      ],
      "metadata": {
        "id": "wky4YPxJfgIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final(fpath):\n",
        "  testset=pd.read_csv(fpath)\n",
        "  testset=testset.drop('Unnamed: 0',axis=1)#assuming that the dataset will be exactly same without class columns\n",
        "  testset=testset.reset_index()#just in case index are not same\n",
        "  testset=testset.drop('index',axis=1)\n",
        "  dataf=torch.tensor(np.array(testset),dtype=torch.float32)\n",
        "  ypred,labelpred=model(dataf)\n",
        "  return labelpred\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "b9JrIyMweLaY"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=final(inputpath)"
      ],
      "metadata": {
        "id": "B7XsOQ0c3ifF"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Kpgq00tT7UoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
